import json
import requests
import time
import re
from collections import defaultdict


def fetch_raw_m3u(url):
    """ä»æŒ‡å®šURLè·å–M3Uå†…å®¹"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"âš ï¸ è·å–æºæ•°æ®å¤±è´¥: {url} - {str(e)}")
        return ""


def parse_m3u(m3u_text):
    """è§£æM3Uæ–‡æœ¬ï¼Œè¿”å›é¢‘é“å…ƒæ•°æ®å’ŒURLçš„åˆ—è¡¨"""
    parsed_channels = []
    lines = m3u_text.strip().splitlines()

    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„M3Uæ–‡ä»¶
    if not lines or not lines[0].startswith("#EXTM3U"):
        print("âŒ æ— æ•ˆçš„M3Uæ–‡ä»¶æ ¼å¼")
        return parsed_channels

    i = 0
    while i < len(lines):
        if lines[i].startswith("#EXTINF"):
            # ä¿å­˜åŸå§‹å…ƒæ•°æ®è¡Œ
            metadata = lines[i]
            url = ""

            # ä¸‹ä¸€ä¸ªåº”è¯¥æ˜¯URL
            if i + 1 < len(lines) and not lines[i + 1].startswith("#"):
                url = lines[i + 1].strip()
                parsed_channels.append({
                    "metadata": metadata,
                    "url": url
                })
                i += 1  # è·³è¿‡URLè¡Œ
        i += 1

    return parsed_channels


def load_json_data(filename):
    """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
        return None


def load_channels():
    """åŠ è½½é¢‘é“åˆ—è¡¨å¹¶ä¿ç•™åŸå§‹é¡ºåºï¼ŒåŒæ—¶æ£€æµ‹é‡å¤é¢‘é“"""
    channels_data = load_json_data('channels.json')
    if not channels_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“åˆ—è¡¨æˆ–æ ¼å¼é”™è¯¯")
        return None, None, None

    # æ”¯æŒæ–°æ ¼å¼ï¼ˆåˆ†ç»„ç»“æ„ï¼‰
    if 'channel_groups' in channels_data:
        channel_list = []
        channel_to_group = {}  # é¢‘é“åˆ°åˆ†ç»„çš„æ˜ å°„
        duplicate_channels = defaultdict(list)  # è®°å½•é‡å¤é¢‘é“åŠå…¶æ‰€åœ¨åˆ†ç»„

        for group in channels_data['channel_groups']:
            group_title = group['group_title']
            for channel in group['channels']:
                channel_list.append(channel)
                # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¯¥é¢‘é“
                if channel in channel_to_group:
                    duplicate_channels[channel].append(group_title)
                channel_to_group[channel] = group_title

        # æ‰“å°é‡å¤é¢‘é“æŠ¥å‘Š
        if duplicate_channels:
            print("\nâš ï¸ å‘ç°é‡å¤é¢‘é“:")
            for channel, groups in duplicate_channels.items():
                original_group = channel_to_group[channel]
                all_groups = [original_group] + groups
                print(f"  é¢‘é“ '{channel}' å‡ºç°åœ¨å¤šä¸ªåˆ†ç»„: {', '.join(all_groups)}")
        else:
            print("\nâœ… æ²¡æœ‰å‘ç°é‡å¤é¢‘é“")

        print(f"éœ€è¦æŸ¥æ‰¾çš„é¢‘é“ ({len(channel_list)})")
        return channel_list, channel_to_group, duplicate_channels

    print("âŒ é¢‘é“åˆ—è¡¨æ ¼å¼é”™è¯¯")
    return None, None, None


def load_sources():
    """åŠ è½½æºåˆ—è¡¨"""
    sources_data = load_json_data('sources.json')
    if not sources_data or 'sources' not in sources_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æºåˆ—è¡¨æˆ–æ ¼å¼é”™è¯¯")
        return None

    sources = sources_data['sources']
    if not sources:
        print("âŒ æºåˆ—è¡¨ä¸ºç©º")
        return None

    print(f"\nå¯ç”¨çš„æº ({len(sources)})")
    return sources


def is_channel_match(channel_name, metadata):
    """
    ç²¾ç¡®åŒ¹é…é¢‘é“åç§°ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
    åŒ¹é…è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰ï¼š
    1. æ£€æŸ¥tvg-idå±æ€§æ˜¯å¦åŒ¹é…é¢‘é“åç§°
    2. æ£€æŸ¥tvg-nameå±æ€§æ˜¯å¦åŒ¹é…é¢‘é“åç§°
    3. æ£€æŸ¥é¢‘é“åç§°æ˜¯å¦åœ¨å…ƒæ•°æ®æœ«å°¾ï¼ˆé€—å·åçš„éƒ¨åˆ†ï¼‰
    4. é¿å…éƒ¨åˆ†åŒ¹é…ï¼ˆå¦‚"CCTV1"ä¸åº”åŒ¹é…"CCTV10"ï¼‰
    """
    # 1. åŒ¹é…tvg-idå±æ€§ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    tvg_id_match = re.search(r'tvg-id="([^"]*)"', metadata, re.IGNORECASE)
    if tvg_id_match:
        tvg_id = tvg_id_match.group(1)
        # ç²¾ç¡®åŒ¹é…tvg-idï¼ˆä½¿ç”¨æ­£åˆ™å¿½ç•¥å¤§å°å†™ï¼‰
        if re.fullmatch(re.escape(channel_name), tvg_id, re.IGNORECASE):
            return True
        # æ£€æŸ¥tvg-idæ˜¯å¦åŒ…å«é¢‘é“åç§°ï¼ˆä½†é¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
        if re.search(rf'\b{re.escape(channel_name)}\b', tvg_id, re.IGNORECASE):
            return True

    # 2. åŒ¹é…tvg-nameå±æ€§
    tvg_name_match = re.search(r'tvg-name="([^"]*)"', metadata, re.IGNORECASE)
    if tvg_name_match:
        tvg_name = tvg_name_match.group(1)
        # ç²¾ç¡®åŒ¹é…tvg-nameï¼ˆä½¿ç”¨æ­£åˆ™å¿½ç•¥å¤§å°å†™ï¼‰
        if re.fullmatch(re.escape(channel_name), tvg_name, re.IGNORECASE):
            return True
        # æ£€æŸ¥tvg-nameæ˜¯å¦åŒ…å«é¢‘é“åç§°ï¼ˆä½†é¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
        if re.search(rf'\b{re.escape(channel_name)}\b', tvg_name, re.IGNORECASE):
            return True

    # 3. åŒ¹é…å…ƒæ•°æ®æœ«å°¾çš„é¢‘é“åç§°ï¼ˆé€—å·åçš„éƒ¨åˆ†ï¼‰
    if ',' in metadata:
        display_name = metadata.split(',')[-1].strip()
        # ç²¾ç¡®åŒ¹é…æ˜¾ç¤ºåç§°ï¼ˆä½¿ç”¨æ­£åˆ™å¿½ç•¥å¤§å°å†™ï¼‰
        if re.fullmatch(re.escape(channel_name), display_name, re.IGNORECASE):
            return True
        # æ£€æŸ¥æ˜¾ç¤ºåç§°æ˜¯å¦åŒ…å«é¢‘é“åç§°
        if re.search(rf'\b{re.escape(channel_name)}\b', display_name, re.IGNORECASE):
            return True

    # 4. åœ¨æ•´ä¸ªå…ƒæ•°æ®ä¸­æœç´¢ï¼ˆä½œä¸ºæœ€åçš„æ‰‹æ®µï¼‰
    if re.search(rf'\b{re.escape(channel_name)}\b', metadata, re.IGNORECASE):
        return True

    return False


def find_channels(sources, channel_list):
    """åœ¨æºåˆ—è¡¨ä¸­æŸ¥æ‰¾é¢‘é“ï¼Œè¿”å›æŸ¥æ‰¾ç»“æœ"""
    found_channel_urls = defaultdict(list)  # é¢‘é“åç§°åˆ°URLåˆ—è¡¨çš„æ˜ å°„
    channel_metadata_map = {}  # é¢‘é“åç§°åˆ°å…ƒæ•°æ®çš„æ˜ å°„
    found_channels = set()  # å·²æ‰¾åˆ°çš„é¢‘é“

    print("\nğŸ” å¼€å§‹æŸ¥æ‰¾é¢‘é“...")

    for source in sources:
        print(f"\nğŸ“¡ æ­£åœ¨æœç´¢æº: {source}")
        m3u_text = fetch_raw_m3u(source)
        if not m3u_text:
            continue

        # è§£æå½“å‰æºçš„M3Uå†…å®¹
        source_channels = parse_m3u(m3u_text)

        # å½“å‰æºä¸­æ‰¾åˆ°çš„æ–°é¢‘é“
        found_in_source = []

        # æŸ¥æ‰¾å½“å‰æºä¸­æ˜¯å¦æœ‰éœ€è¦çš„é¢‘é“
        for channel_name in channel_list:
            # åœ¨å½“å‰æºçš„æ‰€æœ‰é¢‘é“ä¸­æŸ¥æ‰¾åŒ¹é…é¡¹
            for entry in source_channels:
                # æ£€æŸ¥å…ƒæ•°æ®æ˜¯å¦åŒ…å«é¢‘é“åç§°
                if is_channel_match(channel_name, entry["metadata"]):
                    # æ·»åŠ åˆ°æ‰¾åˆ°çš„é¢‘é“URLåˆ—è¡¨
                    found_channel_urls[channel_name].append(entry["url"])

                    # ä¿å­˜å…ƒæ•°æ®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ä¿å­˜è¿‡ï¼‰
                    if channel_name not in channel_metadata_map:
                        channel_metadata_map[channel_name] = entry["metadata"]

                    # æ ‡è®°ä¸ºå·²æ‰¾åˆ°
                    if channel_name not in found_channels:
                        found_channels.add(channel_name)
                        found_in_source.append(channel_name)
                    break

        # è¾“å‡ºå½“å‰æºä¸­æ‰¾åˆ°çš„é¢‘é“
        if found_in_source:
            channels_str = ", ".join(found_in_source)
            print(f"âœ… æ‰¾åˆ°é¢‘é“: {channels_str}")
        else:
            print("âš ï¸ åœ¨æ­¤æºä¸­æœªæ‰¾åˆ°æ–°é¢‘é“")

        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)

    # è®¡ç®—ç¼ºå¤±é¢‘é“
    missing_channel_list = [ch for ch in channel_list if ch not in found_channels]

    return found_channel_urls, channel_metadata_map, missing_channel_list


def extract_tvg_name(metadata):
    """ä»å…ƒæ•°æ®ä¸­æå–tvg-name"""
    match = re.search(r'tvg-name="([^"]*)"', metadata)
    if match:
        return match.group(1)
    return None


def set_group_title(metadata, group_title):
    """è®¾ç½®æˆ–æ›¿æ¢å…ƒæ•°æ®ä¸­çš„group-titleå±æ€§ï¼Œç¡®ä¿å®Œå…¨ç§»é™¤åŸæœ‰çš„group-title"""
    # é¦–å…ˆç§»é™¤æ‰€æœ‰ç°æœ‰çš„group-titleå±æ€§ï¼ˆåŒ…æ‹¬å•å¼•å·å’ŒåŒå¼•å·ï¼‰
    metadata = re.sub(r'group-title=[\'"][^\'"]*[\'"]', '', metadata)
    metadata = re.sub(r'\s+', ' ', metadata).strip()

    # åœ¨é€—å·å‰æ·»åŠ æ–°çš„group-titleå±æ€§
    if ',' in metadata:
        parts = metadata.split(',', 1)
        new_metadata = f'{parts[0]} group-title="{group_title}",{parts[1]}'
    else:
        new_metadata = f'{metadata} group-title="{group_title}"'

    return new_metadata


def generate_unique_tvg_name(metadata, source_index):
    """ç”Ÿæˆå”¯ä¸€çš„tvg-nameï¼Œé¿å…é‡å¤"""
    # æå–åŸå§‹tvg-name
    original_tvg_name = extract_tvg_name(metadata)

    if original_tvg_name:
        # ç§»é™¤ç°æœ‰çš„tvg-name
        metadata = re.sub(r'tvg-name="[^"]*"', '', metadata)
        metadata = re.sub(r'\s+', ' ', metadata).strip()

        # æ·»åŠ å¸¦æºç¼–å·çš„å”¯ä¸€tvg-name
        if ',' in metadata:
            parts = metadata.split(',', 1)
            new_metadata = f'{parts[0]} tvg-name="{original_tvg_name}_æº{source_index}",{parts[1]}'
        else:
            new_metadata = f'{metadata} tvg-name="{original_tvg_name}_æº{source_index}"'
    else:
        # å¦‚æœæ²¡æœ‰tvg-nameï¼Œåœ¨é¢‘é“åç§°ä¸­æ·»åŠ æºæ ‡è¯†
        if ',' in metadata:
            parts = metadata.split(',', 1)
            new_metadata = f'{parts[0]} tvg-name="é¢‘é“_æº{source_index}",{parts[1]}'
        else:
            new_metadata = f'{metadata} tvg-name="é¢‘é“_æº{source_index}"'

    return new_metadata


def generate_m3u_file(found_channel_urls, channel_list, channel_metadata_map, channel_to_group):
    """ç”Ÿæˆæœ€ç»ˆçš„M3Uæ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰æ‰¾åˆ°çš„é¢‘é“URL"""
    print("\nğŸ“ ç”Ÿæˆç»“æœæ–‡ä»¶...")
    with open('simple.m3u', 'w', encoding='utf-8') as f:
        # å†™å…¥M3Uå¤´éƒ¨
        f.write("#EXTM3U\n")

        # æŒ‰ç…§åŸå§‹é¡ºåºå†™å…¥é¢‘é“
        for channel_name in channel_list:
            if channel_name in found_channel_urls:
                # è·å–åˆ†ç»„åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
                group_title = channel_to_group.get(channel_name) if channel_to_group else None

                # è·å–è¯¥é¢‘é“çš„æ‰€æœ‰URL
                urls = found_channel_urls[channel_name]

                # ä¸ºæ¯ä¸ªURLå†™å…¥ä¸€ä¸ªæ¡ç›®
                for i, url in enumerate(urls):
                    # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®
                    if channel_name in channel_metadata_map:
                        metadata = channel_metadata_map[channel_name]

                        # å¦‚æœæœ‰åˆ†ç»„åç§°ï¼Œè®¾ç½®æˆ–æ›¿æ¢group-title
                        if group_title:
                            metadata = set_group_title(metadata, group_title)

                        # ç¡®ä¿tvg-nameå”¯ä¸€æ€§
                        metadata = generate_unique_tvg_name(metadata, i + 1)

                        # ä½¿ç”¨å¤„ç†åçš„å…ƒæ•°æ®æ ¼å¼
                        f.write(f"{metadata}\n")
                    else:
                        # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œåˆ›å»ºæ–°çš„å…ƒæ•°æ®è¡Œ
                        if group_title:
                            f.write(
                                f'#EXTINF:-1 group-title="{group_title}" tvg-name="{channel_name}_æº{i + 1}", {channel_name}\n')
                        else:
                            f.write(
                                f'#EXTINF:-1 tvg-name="{channel_name}_æº{i + 1}", {channel_name}\n')

                    f.write(f"{url}\n")


def print_report(found_channel_urls, channel_list, missing_channel_list):
    """æ‰“å°è¯¦ç»†æŠ¥å‘Š"""
    found_count = len(found_channel_urls)
    total_count = len(channel_list)

    # è®¡ç®—æ€»URLæ•°é‡
    total_urls = sum(len(urls) for urls in found_channel_urls.values())

    # æ‰“å°æ¯ä¸ªé¢‘é“æ‰¾åˆ°çš„æºæ•°é‡
    print("\nğŸ“Š å„é¢‘é“æºæ•°é‡ç»Ÿè®¡:")
    for channel_name in sorted(found_channel_urls.keys()):
        url_count = len(found_channel_urls[channel_name])
        print(f"  {channel_name}: {url_count}ä¸ªæº")

    print("\n" + "=" * 50)
    print(f"ğŸ” æŸ¥æ‰¾ç»“æœç»Ÿè®¡:")
    print(f"  æ‰¾åˆ°é¢‘é“: {found_count}/{total_count}")
    print(f"  æ€»URLæ•°é‡: {total_urls}")
    print(f"  æœªæ‰¾åˆ°é¢‘é“: {len(missing_channel_list)}")

    if missing_channel_list:
        print("\nâš ï¸ æœªæ‰¾åˆ°çš„é¢‘é“åˆ—è¡¨:")
        for idx, channel_name in enumerate(missing_channel_list, 1):
            print(f"  {idx}. {channel_name}")
    else:
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰é¢‘é“å‡å·²æˆåŠŸæ‰¾åˆ°")

    print("=" * 50)


def main():
    # 1. åŠ è½½é¢‘é“åˆ—è¡¨å’Œåˆ†ç»„æ˜ å°„åŠé‡å¤é¢‘é“ä¿¡æ¯
    channel_list, channel_to_group, duplicate_channels = load_channels()
    if not channel_list:
        return

    # 2. åŠ è½½æºåˆ—è¡¨
    sources = load_sources()
    if not sources:
        return

    # 3. åœ¨æºä¸­æŸ¥æ‰¾é¢‘é“
    found_channel_urls, channel_metadata_map, missing_channel_list = find_channels(sources,
                                                                                   channel_list)

    # 4. ç”ŸæˆM3Uæ–‡ä»¶
    generate_m3u_file(found_channel_urls, channel_list, channel_metadata_map, channel_to_group)

    # 5. æ‰“å°æŠ¥å‘Š
    print_report(found_channel_urls, channel_list, missing_channel_list)


if __name__ == '__main__':
    main()